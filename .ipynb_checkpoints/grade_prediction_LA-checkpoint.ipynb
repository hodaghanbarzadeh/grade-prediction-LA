{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('./static/data/dataset_stu.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    sex  age  traveltime  studytime  failures schoolsup famsup paid  \\\n",
      "0     F   18           2          2         0       yes     no   no   \n",
      "1     F   17           1          2         0        no    yes   no   \n",
      "2     F   15           1          2         0       yes     no   no   \n",
      "3     F   15           1          3         0        no    yes   no   \n",
      "4     F   16           1          2         0        no    yes   no   \n",
      "..   ..  ...         ...        ...       ...       ...    ...  ...   \n",
      "644   F   19           1          3         1        no     no   no   \n",
      "645   F   18           1          2         0        no    yes   no   \n",
      "646   F   18           2          2         0        no     no   no   \n",
      "647   M   17           2          1         0        no     no   no   \n",
      "648   M   18           3          1         0        no     no   no   \n",
      "\n",
      "    activities higher internet  famrel  freetime  goout  health  absences  \\\n",
      "0           no    yes       no       4         3      4       3         4   \n",
      "1           no    yes      yes       5         3      3       3         2   \n",
      "2           no    yes      yes       4         3      2       3         6   \n",
      "3          yes    yes      yes       3         2      2       5         0   \n",
      "4           no    yes       no       4         3      2       5         0   \n",
      "..         ...    ...      ...     ...       ...    ...     ...       ...   \n",
      "644        yes    yes      yes       5         4      2       5         4   \n",
      "645         no    yes      yes       4         3      4       1         4   \n",
      "646        yes    yes       no       1         1      1       5         6   \n",
      "647         no    yes      yes       2         4      5       2         6   \n",
      "648         no    yes      yes       4         4      1       5         4   \n",
      "\n",
      "     grade  \n",
      "0       11  \n",
      "1       11  \n",
      "2       12  \n",
      "3       14  \n",
      "4       13  \n",
      "..     ...  \n",
      "644     10  \n",
      "645     16  \n",
      "646      0  \n",
      "647     10  \n",
      "648     11  \n",
      "\n",
      "[649 rows x 17 columns]\n"
     ]
    }
   ],
   "source": [
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "grades = dataset['grade'].values\n",
    "labels = []\n",
    "\n",
    "for grade in grades:\n",
    "    if grade >=17:\n",
    "        labels.append('very good')\n",
    "    elif grade < 17 and grade >= 15:\n",
    "        labels.append('good')\n",
    "    elif grade < 15 and grade >= 10:\n",
    "        labels.append('average')\n",
    "    elif grade < 10:\n",
    "        labels.append('bad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['average', 'average', 'average', 'average', 'average', 'average', 'average', 'average', 'very good', 'average', 'average', 'average', 'average', 'average', 'good', 'very good', 'average', 'average', 'bad', 'average', 'average', 'average', 'average', 'average', 'average', 'average', 'average', 'average', 'average', 'average', 'average', 'good', 'good', 'average', 'average', 'average', 'average', 'average', 'average', 'average', 'average', 'average', 'good', 'average', 'average', 'average', 'average', 'very good', 'average', 'average', 'average', 'good', 'bad', 'average', 'average', 'average', 'good', 'good', 'average', 'good', 'good', 'good', 'average', 'average', 'average', 'good', 'average', 'average', 'average', 'good', 'average', 'average', 'average', 'average', 'average', 'average', 'average', 'average', 'average', 'average', 'average', 'bad', 'average', 'average', 'average', 'average', 'average', 'good', 'average', 'average', 'average', 'average', 'average', 'average', 'average', 'average', 'average', 'average', 'average', 'average', 'bad', 'good', 'average', 'average', 'good', 'average', 'average', 'average', 'average', 'average', 'average', 'average', 'average', 'very good', 'average', 'average', 'good', 'good', 'average', 'average', 'average', 'average', 'average', 'average', 'average', 'bad', 'average', 'average', 'good', 'average', 'average', 'bad', 'average', 'average', 'average', 'average', 'average', 'average', 'average', 'good', 'average', 'average', 'average', 'average', 'average', 'average', 'average', 'average', 'bad', 'average', 'bad', 'average', 'average', 'average', 'average', 'bad', 'average', 'average', 'average', 'average', 'average', 'bad', 'average', 'bad', 'average', 'average', 'average', 'average', 'bad', 'average', 'average', 'average', 'bad', 'average', 'bad', 'bad', 'average', 'bad', 'bad', 'bad', 'average', 'very good', 'average', 'very good', 'average', 'very good', 'average', 'average', 'good', 'average', 'average', 'average', 'average', 'average', 'average', 'average', 'very good', 'average', 'good', 'average', 'average', 'good', 'average', 'average', 'average', 'average', 'average', 'average', 'average', 'good', 'average', 'average', 'good', 'average', 'good', 'average', 'good', 'average', 'average', 'bad', 'average', 'good', 'average', 'average', 'average', 'average', 'average', 'average', 'average', 'good', 'average', 'average', 'average', 'average', 'average', 'average', 'average', 'average', 'good', 'bad', 'very good', 'average', 'average', 'good', 'average', 'average', 'average', 'average', 'bad', 'average', 'good', 'average', 'average', 'average', 'average', 'bad', 'bad', 'bad', 'good', 'average', 'average', 'average', 'bad', 'bad', 'average', 'good', 'average', 'good', 'average', 'good', 'good', 'average', 'good', 'average', 'average', 'average', 'good', 'average', 'average', 'bad', 'average', 'average', 'bad', 'average', 'bad', 'average', 'average', 'average', 'average', 'very good', 'average', 'average', 'average', 'average', 'average', 'average', 'good', 'average', 'average', 'average', 'good', 'average', 'average', 'average', 'average', 'bad', 'good', 'average', 'average', 'average', 'average', 'average', 'good', 'average', 'very good', 'good', 'good', 'average', 'average', 'average', 'average', 'good', 'average', 'average', 'average', 'average', 'average', 'very good', 'average', 'average', 'average', 'average', 'very good', 'average', 'good', 'very good', 'good', 'very good', 'very good', 'good', 'good', 'average', 'average', 'very good', 'very good', 'good', 'average', 'bad', 'good', 'very good', 'average', 'good', 'average', 'average', 'good', 'average', 'very good', 'very good', 'good', 'very good', 'average', 'average', 'average', 'average', 'very good', 'very good', 'average', 'average', 'average', 'average', 'bad', 'average', 'average', 'average', 'very good', 'good', 'average', 'average', 'very good', 'average', 'average', 'good', 'average', 'average', 'average', 'average', 'good', 'good', 'average', 'average', 'average', 'average', 'good', 'good', 'good', 'average', 'very good', 'average', 'average', 'very good', 'very good', 'average', 'average', 'good', 'good', 'average', 'average', 'average', 'average', 'good', 'very good', 'good', 'very good', 'average', 'good', 'average', 'very good', 'very good', 'average', 'average', 'very good', 'average', 'average', 'average', 'average', 'average', 'average', 'very good', 'bad', 'average', 'average', 'average', 'bad', 'average', 'average', 'average', 'bad', 'average', 'average', 'good', 'bad', 'bad', 'average', 'bad', 'average', 'bad', 'average', 'bad', 'very good', 'average', 'good', 'average', 'average', 'bad', 'bad', 'bad', 'good', 'average', 'average', 'average', 'average', 'average', 'average', 'average', 'average', 'bad', 'average', 'average', 'average', 'average', 'average', 'average', 'good', 'average', 'average', 'average', 'bad', 'average', 'bad', 'average', 'average', 'average', 'bad', 'average', 'bad', 'average', 'average', 'average', 'bad', 'average', 'average', 'bad', 'average', 'average', 'bad', 'average', 'average', 'average', 'average', 'good', 'bad', 'average', 'bad', 'average', 'average', 'average', 'average', 'average', 'bad', 'very good', 'very good', 'average', 'bad', 'bad', 'bad', 'average', 'good', 'good', 'bad', 'bad', 'bad', 'average', 'bad', 'bad', 'bad', 'good', 'average', 'average', 'bad', 'average', 'bad', 'average', 'bad', 'good', 'average', 'average', 'average', 'average', 'average', 'average', 'average', 'average', 'average', 'bad', 'average', 'bad', 'good', 'average', 'average', 'very good', 'average', 'average', 'average', 'average', 'average', 'average', 'average', 'average', 'average', 'average', 'average', 'average', 'average', 'bad', 'average', 'bad', 'bad', 'bad', 'bad', 'bad', 'bad', 'bad', 'bad', 'average', 'average', 'average', 'average', 'average', 'average', 'bad', 'average', 'bad', 'bad', 'bad', 'average', 'bad', 'bad', 'bad', 'bad', 'average', 'bad', 'average', 'average', 'average', 'very good', 'very good', 'very good', 'bad', 'average', 'average', 'average', 'average', 'average', 'bad', 'average', 'bad', 'very good', 'average', 'average', 'average', 'bad', 'good', 'average', 'average', 'average', 'good', 'average', 'very good', 'good', 'average', 'good', 'average', 'bad', 'good', 'bad', 'average', 'bad', 'average', 'average', 'bad', 'very good', 'average', 'bad', 'average', 'good', 'bad', 'very good', 'bad', 'good', 'bad', 'bad', 'good', 'average', 'average', 'average', 'good', 'bad', 'average', 'average']\n"
     ]
    }
   ],
   "source": [
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoding the data\n",
    "enc = LabelEncoder()\n",
    "for item in dataset:\n",
    "    data_raw = dataset[item].values\n",
    "    dataset[item] = enc.fit_transform(data_raw)\n",
    "\n",
    "enc_labels = enc.fit_transform(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     sex  age  traveltime  studytime  failures  schoolsup  famsup  paid  \\\n",
      "0      0    3           1          1         0          1       0     0   \n",
      "1      0    2           0          1         0          0       1     0   \n",
      "2      0    0           0          1         0          1       0     0   \n",
      "3      0    0           0          2         0          0       1     0   \n",
      "4      0    1           0          1         0          0       1     0   \n",
      "..   ...  ...         ...        ...       ...        ...     ...   ...   \n",
      "644    0    4           0          2         1          0       0     0   \n",
      "645    0    3           0          1         0          0       1     0   \n",
      "646    0    3           1          1         0          0       0     0   \n",
      "647    1    2           1          0         0          0       0     0   \n",
      "648    1    3           2          0         0          0       0     0   \n",
      "\n",
      "     activities  higher  internet  famrel  freetime  goout  health  absences  \\\n",
      "0             0       1         0       3         2      3       2         4   \n",
      "1             0       1         1       4         2      2       2         2   \n",
      "2             0       1         1       3         2      1       2         6   \n",
      "3             1       1         1       2         1      1       4         0   \n",
      "4             0       1         0       3         2      1       4         0   \n",
      "..          ...     ...       ...     ...       ...    ...     ...       ...   \n",
      "644           1       1         1       4         3      1       4         4   \n",
      "645           0       1         1       3         2      3       0         4   \n",
      "646           1       1         0       0         0      0       4         6   \n",
      "647           0       1         1       1         3      4       1         6   \n",
      "648           0       1         1       3         3      0       4         4   \n",
      "\n",
      "     grade  \n",
      "0        8  \n",
      "1        8  \n",
      "2        9  \n",
      "3       11  \n",
      "4       10  \n",
      "..     ...  \n",
      "644      7  \n",
      "645     13  \n",
      "646      0  \n",
      "647      7  \n",
      "648      8  \n",
      "\n",
      "[649 rows x 17 columns]\n"
     ]
    }
   ],
   "source": [
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 3 1 ... 2 4 8]\n",
      " [0 2 0 ... 2 2 8]\n",
      " [0 0 0 ... 2 6 9]\n",
      " ...\n",
      " [0 3 1 ... 4 6 0]\n",
      " [1 2 1 ... 1 6 7]\n",
      " [1 3 2 ... 4 4 8]]\n"
     ]
    }
   ],
   "source": [
    "print(dataset.values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=dataset.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(dataset[:,:16],enc_labels, stratify=enc_labels,random_state=0,test_size=0.20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_data = [[1,1,2,1,2,1,2,2,1,2,1,1,2,1,2,1]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision score: 0.488866\n",
      "Prediction Accuracy: 0.630769\n",
      "Recall score: 0.297421\n",
      "F1 score: 0.292118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:938: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "    lr = LogisticRegression()\n",
    "    lr.fit(X_train, y_train)\n",
    "    y_pred = lr.predict(X_test)\n",
    "    print('Precision score: {:3f}'.format(precision_score(y_test, y_pred, average='macro')))\n",
    "    print('Prediction Accuracy: {:3f}'.format(accuracy_score(y_test, y_pred)))\n",
    "    print('Recall score: {:3f}'.format(recall_score(y_test, y_pred, average='macro')))\n",
    "    print('F1 score: {:3f}'.format(f1_score(y_test, y_pred, average='macro')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision score: 0.256910\n",
      "Prediction Accuracy: 0.584615\n",
      "Recall score: 0.256968\n",
      "F1 score: 0.239965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "    knn.fit(X_train, y_train)\n",
    "    y_pred = knn.predict(X_test)\n",
    "    print('Precision score: {:3f}'.format(precision_score(y_test, y_pred, average='macro')))\n",
    "    print('Prediction Accuracy: {:3f}'.format(accuracy_score(y_test, y_pred)))\n",
    "    print('Recall score: {:3f}'.format(recall_score(y_test, y_pred, average='macro')))\n",
    "    print('F1 score: {:3f}'.format(f1_score(y_test, y_pred, average='macro')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictFunction(data_predicit):\n",
    "    result =lr.predict(data_predicit)\n",
    "    if result[0] == 0:\n",
    "        return 'Average'\n",
    "    if result[0] == 1:\n",
    "        return 'Bad'\n",
    "    if result[0] == 2:\n",
    "        return 'Good'\n",
    "    if result[0] == 3:\n",
    "        return 'Very good'\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Average'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictFunction(validation_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
